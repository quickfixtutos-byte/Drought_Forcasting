{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this dataset, we are working with monthly environmental indices:\n",
    "\n",
    "- LST *(Land Surface Temperature)*,\n",
    "- NDVI *(Normalized Difference Vegetation Index)*,\n",
    "- SM *(Soil Moisture)*,\n",
    "- SPI *(Standardized Precipitation Index)*.\n",
    "\n",
    "Before we dive into the code, we will need the following libraries:\n",
    "\n",
    "- **Rasterio:** To read .tif files and extract spatial metadata.\n",
    "- **Xarray:** To stack these 2D images into a 3D \"Data Cube\" (Time, Lat, Lon).\n",
    "- **Matplotlib/Seaborn:** For visualization.\n",
    "\n",
    "---\n",
    "\n",
    "# 0. Initial Setup\n",
    "\n",
    "## 0.1. Environment Installation\n",
    "\n",
    "We need specialized geospatial libraries to handle coordinate systems and reproject the different data layers so they line up perfectly over Tunisia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script rio.exe is installed in 'C:\\Users\\moota\\AppData\\Roaming\\Python\\Python314\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# Install rasterio for geospatial data handling\n",
    "!pip install -q rasterio\n",
    "# Install rioxarray for automatic CRS handling and reprojection\n",
    "!pip install -q rioxarray regionmask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Library Imports\n",
    "\n",
    "We load the standard data science stack along with `rioxarray` for geographic processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import glob\n",
    "import re\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rioxarray\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3. Helper Functions\n",
    "\n",
    "These functions handle the messy parts of the data: extracting dates from your specific filenames and ensuring the spatial orientation (North/South) is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_from_filename(filename):\n",
    "    \"\"\"Parses year and month from string (e.g., '2023_01')\"\"\"\n",
    "    match = re.search(r'(\\d{4})_(\\d{2})', filename)\n",
    "    return f\"{match.group(1)}-{match.group(2)}-01\" if match else None\n",
    "\n",
    "def load_and_project(base_path, folder_name, var_label, reference_da=None):\n",
    "    \"\"\"Loads TIFs, reprojects to UTM 32N, and aligns to a master grid.\"\"\"\n",
    "    # Search for files\n",
    "    search_pattern = os.path.join(base_path, folder_name, \"**/*.tif\")\n",
    "    files = sorted(glob.glob(search_pattern, recursive=True))\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"⚠️ No files found for {var_label}\")\n",
    "        return None\n",
    "\n",
    "    # Target CRS for Tunisia: UTM Zone 32N\n",
    "    TARGET_CRS = \"EPSG:32632\"\n",
    "    da_list = []\n",
    "    \n",
    "    for f in files:\n",
    "        date_str = extract_date_from_filename(os.path.basename(f))\n",
    "        if not date_str: continue\n",
    "            \n",
    "        # Open with rioxarray (automatically handles orientation)\n",
    "        da = rioxarray.open_rasterio(f, masked=True).squeeze()\n",
    "        \n",
    "        # Reproject to Metric UTM 32N\n",
    "        if reference_da is None:\n",
    "            # First variable (LST) defines the \"Master Grid\"\n",
    "            da = da.rio.reproject(TARGET_CRS, resampling=Resampling.bilinear)\n",
    "        else:\n",
    "            # Match all others to the Master Grid pixel-for-pixel\n",
    "            da = da.rio.reproject_match(reference_da, resampling=Resampling.bilinear)\n",
    "            \n",
    "        da = da.expand_dims(time=[pd.to_datetime(date_str)])\n",
    "        da_list.append(da)\n",
    "    \n",
    "    full_da = xr.concat(da_list, dim='time').rename(var_label)\n",
    "    print(f\"✅ {var_label} loaded & aligned. Shape: {full_da.shape}\")\n",
    "    return full_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4. Unified Data Loading\n",
    "\n",
    "This cell creates your \"Data Cube.\" It uses LST as the spatial reference and forces NDVI, Soil Moisture, and SPI to align to it. This solves the \"backwards\" and \"distorted\" issues by using a metric coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No files found for LST\n",
      "⚠️ No files found for NDVI\n",
      "⚠️ No files found for Soil_Moisture\n",
      "⚠️ No files found for SPI\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "objects must be an iterable containing only DataTree(s), Dataset(s), DataArray(s), and dictionaries: [None, None, None, None]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m spi_final  = load_and_project(INPUT_PATH, \u001b[33m'\u001b[39m\u001b[33mSPI\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSPI\u001b[39m\u001b[33m'\u001b[39m, reference_da=lst_final)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 3. Final Merge\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m ds = \u001b[43mxr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlst_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndvi_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msm_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspi_final\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minner\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Final Structured Dataset ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m display(ds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\xarray\\structure\\merge.py:1126\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(objects, compat, join, fill_value, combine_attrs)\u001b[39m\n\u001b[32m   1124\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m objects:\n\u001b[32m   1125\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, DataArray | Dataset | Coordinates | \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1126\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   1127\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mobjects must be an iterable containing only DataTree(s), \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1128\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset(s), DataArray(s), and dictionaries: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobjects\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1129\u001b[39m         )\n\u001b[32m   1131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, DataArray):\n\u001b[32m   1132\u001b[39m         obj = obj.to_dataset(promote_attrs=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: objects must be an iterable containing only DataTree(s), Dataset(s), DataArray(s), and dictionaries: [None, None, None, None]"
     ]
    }
   ],
   "source": [
    "# Update path to your Kaggle input\n",
    "INPUT_PATH = '/Downloads/drouddght_data/'\n",
    "\n",
    "# 1. Load Master Grid (LST)\n",
    "lst_final = load_and_project(INPUT_PATH, 'LST', 'LST')\n",
    "\n",
    "# 2. Align others to LST\n",
    "ndvi_final = load_and_project(INPUT_PATH, 'NDVI', 'NDVI', reference_da=lst_final)\n",
    "sm_final   = load_and_project(INPUT_PATH, 'SM', 'Soil_Moisture', reference_da=lst_final)\n",
    "spi_final  = load_and_project(INPUT_PATH, 'SPI', 'SPI', reference_da=lst_final)\n",
    "\n",
    "# 3. Final Merge\n",
    "ds = xr.merge([lst_final, ndvi_final, sm_final, spi_final], join='inner')\n",
    "\n",
    "print(\"\\n--- Final Structured Dataset ---\")\n",
    "display(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5. Spatial & Orientation Verification\n",
    "\n",
    "We plot a quick map to ensure Tunisia is right-side up and the aspect ratio is correct (not squashed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 9))\n",
    "ds['NDVI'].isel(time=0).plot(cmap='YlGn', robust=True)\n",
    "\n",
    "# Force metric 1:1 aspect ratio\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.title(\"Spatial Verification: Tunisia (UTM 32N)\")\n",
    "plt.xlabel(\"Easting (m)\")\n",
    "plt.ylabel(\"Northing (m)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Understanding the Dataset\n",
    "\n",
    "## 1.1. Data Source Audit & Reliability Analysis\n",
    "\n",
    "Before building an uncertainty-aware forecasting model, we must establish how much \"belief\" we can place in each variable. In the context of Evidence Theory (\"Smets\" or \"Dubois-Prade\") or Possibility Theory, we treat these sensors not just as numbers, but as \"mass functions\" of evidence.\n",
    "\n",
    "- **LST & NDVI:** High-resolution optical data. Very reliable for current state, but \"stale\" if clouds were present during the satellite overpass.\n",
    "- **Soil Moisture (SM):** Often a blend of satellite microwave data and land-surface models. It has higher \"epistemic uncertainty\" (model bias).\n",
    "- **SPI:** A purely mathematical transformation of precipitation. Its uncertainty comes from the density of the weather stations used to interpolate the rain map.\n",
    "\n",
    "In this cell, we check for **Data Overlap** *(do sources disagree?)* and define our **Reliability Weights** which will later inform our uncertainty-aware model *(e.g., using Evidence Theory)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Data Source & Reliability Audit\n",
    "\n",
    "# In UTM projection, coordinates are named 'x' and 'y'\n",
    "total_pixels = ds.x.size * ds.y.size\n",
    "\n",
    "# Checking for Spatial Disagreement (Mask Mismatch)\n",
    "# This identifies if different sensors have different 'NoData' areas (e.g., coastal pixels)\n",
    "nan_mask = ds.isnull()\n",
    "disagreement_map = nan_mask.LST != nan_mask.NDVI\n",
    "\n",
    "print(f\"Total Grid Pixels: {total_pixels}\")\n",
    "print(f\"Spatial Disagreement: {disagreement_map.sum().values.max()} pixels\")\n",
    "\n",
    "# Defining Reliability Factors (Basic Probability Assignments for Evidence Theory)\n",
    "# These represent our 'Source Trust' coefficients\n",
    "reliability_factors = {\n",
    "    \"LST\": 0.85,          # High trust in thermal bands\n",
    "    \"NDVI\": 0.90,         # Gold standard for vegetation state\n",
    "    \"Soil_Moisture\": 0.70, # Lower trust due to model-based estimation\n",
    "    \"SPI\": 0.80           # High trust, but statistically derived\n",
    "}\n",
    "\n",
    "# Summary of Time-Step Continuity\n",
    "expected_months = pd.date_range(start=ds.time.min().values, \n",
    "                                end=ds.time.max().values, \n",
    "                                freq='MS')\n",
    "missing_months = expected_months.difference(ds.time.values)\n",
    "\n",
    "print(f\"Temporal Coverage: {len(ds.time)} / {len(expected_months)} months\")\n",
    "if not missing_months.empty:\n",
    "    print(f\"⚠️ Warning: Missing months detected: {missing_months}\")\n",
    "else:\n",
    "    print(\"✅ Time series is temporally continuous.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That **Spatial Disagreement (298,301 pixels)** is a massive red flag. Out of ~349k pixels, nearly 85% of your grid has \"disagreement\" in where data is valid (NaN values).\n",
    "\n",
    "This tells us that your sources have very different \"masks.\" For example, the Soil Moisture model might provide data over the desert where the NDVI sensor (which looks for greenness) sees \"No Data,\" or the SPI dataset has a slightly different coastline. For an uncertainty-aware model, this means we must be very careful not to \"hallucinate\" relationships in areas where only one sensor is active.\n",
    "\n",
    "## 1.2. Individual Feature Temporal Dynamics\n",
    "\n",
    "To understand the \"character\" of our features, we need to see them as a human would. We are looking for:\n",
    "\n",
    "1. **Seasonality:** Is the signal dominated by the calendar?\n",
    "\n",
    "2. **Noise:** Does LST have spikes that look like sensor errors?\n",
    "\n",
    "3. **Range:** Are the scales comparable (e.g., NDVI is 0 to 1, but LST is in Kelvin/Celsius)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Temporal Visualization of Features\n",
    "\n",
    "# Calculate the national spatial mean for each variable\n",
    "df_features = ds.mean(dim=['x', 'y']).to_dataframe()\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 14), sharex=True)\n",
    "feature_list = [\n",
    "    ('LST', 'Red', 'Land Surface Temp'),\n",
    "    ('NDVI', 'Green', 'Vegetation Index'),\n",
    "    ('Soil_Moisture', 'Purple', 'Soil Moisture'),\n",
    "    ('SPI', 'Blue', 'Standardized Precip Index')\n",
    "]\n",
    "\n",
    "for i, (col, color, title) in enumerate(feature_list):\n",
    "    axes[i].plot(df_features.index, df_features[col], color=color, lw=1.5)\n",
    "    axes[i].set_title(f\"National Temporal Trend: {title}\", fontsize=12, loc='left')\n",
    "    axes[i].set_ylabel(\"Value\")\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Adding a rolling mean to visualize the long-term trend behind the seasonality\n",
    "    axes[i].plot(df_features.index, df_features[col].rolling(12, center=True).mean(), \n",
    "                color='black', linestyle='--', alpha=0.8, label='12-Month Trend')\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display basic statistics to understand scaling needs\n",
    "print(\"--- Statistical Summary ---\")\n",
    "display(df_features.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis for Model Selection:**\n",
    "\n",
    "- **The \"Memory\" Effect:** Notice how SPI and Soil Moisture fluctuate rapidly, while NDVI has a smoother, slightly lagged curve. This suggests our model needs memory (like an LSTM or a Transformer).\n",
    "- **Stationarity:** LST is highly stationary (predictable cycles), while SPI is stochastic (random).\n",
    "- **Uncertainty Application:** Since your spatial disagreement is high, Possibility Theory might be more robust than Evidence Theory here. Possibility Theory allows us to define \"imprecise\" boundaries for pixels that are near the edge of a sensor's mask, whereas Evidence Theory (\"Smets\" or \"Dubois-Prade\") might struggle if the \"conflict\" between sources is too high due to missing data.\n",
    "\n",
    "**Analysis of Statistical Distributions:**\n",
    "\n",
    "- **LST (Mean: 31.89°C, Max: 47.52°C):** These values are in Celsius. A mean of ~32°C suggests a hot, arid climate (consistent with Tunisia), but a maximum of 47.5°C indicates extreme heat stress. The high standard deviation (10.13) confirms strong seasonal swings between winter and summer.\n",
    "- **NDVI (Mean: 0.177, Max: 0.240):** This range is quite low. In healthy Mediterranean forests, NDVI can reach 0.6–0.8. A max of 0.24 means your dataset is dominated by sparse vegetation, olive groves, or arid lands. This small \"dynamic range\" (0.13 to 0.24) means the model must be very sensitive to small changes.\n",
    "- **Soil_Moisture (Mean: 7.69, Max: 12.16):** These units are likely $kg/m^2$ (common in GLDAS/Noah models) rather than volumetric percentages ($m^3/m^3$). If we assume a 10cm soil layer, 7.69 $kg/m^2$ is roughly 7.6% volumetric moisture, which is extremely dry—typical for Tunisian topsoil.\n",
    "- **SPI (Mean: -0.03, Min: -1.42, Max: 2.47):** SPI is a unitless standard deviation.\n",
    "  - **SPI = 0** is the historical average.\n",
    "  - **SPI < -1.0** indicates \"Moderately Dry.\"\n",
    "  - **SPI < -1.5** is \"Severely Dry.\"\n",
    "  - Your minimum of -1.42 suggests you have captured moderate-to-severe drought events, but perhaps not the \"Exceptional\" droughts (SPI < -2.0) that occurred in very recent years.\n",
    "\n",
    "**Observations on \"Band\" and \"Spatial_Ref\":**\n",
    "\n",
    "- **Band (Mean: 1.0):** This is a metadata artifact from the .tif loading process. It just confirms every file has 1 band. This column can be ignored/dropped during preprocessing.\n",
    "- **Spatial_Ref (Mean: 0.0):** This is a coordinate placeholder for the UTM 32N projection information. It contains no variable data.\n",
    "\n",
    "**Decision for Modeling:**\n",
    "\n",
    "The data is on completely different scales (LST goes up to 47, NDVI is 0.2). This confirms that normalization is mandatory. However, since we want to be \"uncertainty aware,\" we should not just use a simple Min-Max scaler. We should consider a **Z-score (StandardScaler)** because SPI is already standardized; putting the other variables on a similar \"standard deviation\" scale will make the Theory of Evidence fusion much more mathematically stable.\n",
    "\n",
    "**Hybrid Evidential-Possibilistic Model:**\n",
    "\n",
    "1. **Transferable Belief Model (TBM):** Proposed by Philippe Smets. It doesn't force the data to 100%. If sensors conflict, it assigns that conflict to the Empty Set ($\\varnothing$), which we interpret as \"The sensors are broken/conflicting.\" This is a huge \"Warning Light\" for your model.\n",
    "2. **Possibility Theory (Maxitive Fusion):** Instead of multiplying (which amplifies conflict), Possibility Theory uses a `max` operator. If one sensor says 1.0 and another says 0.0, the \"Possibility\" stays 1.0. It is much more \"tolerant\" of disagreement.\n",
    "3. **Conflict Redistribution (PCR6):** This is the modern standard. It takes that \"conflicting mass\" and shares it back among the sensors based on their individual reliability, rather than throwing it into a 1% event.\n",
    "\n",
    "## 1.3. Spatio-Temporal Field Visualization (Animated)\n",
    "\n",
    "We will use `matplotlib.animation` to create a sequence. Since different variables represent different physical processes, we'll use specific colormaps:\n",
    "\n",
    "- **LST:** `inferno` (perceptually uniform for heat).\n",
    "- **NDVI:** `YlGn` (Yellow to Green for vegetation health).\n",
    "- **Soil Moisture:** `Blues` (Light to deep water content).\n",
    "- **SPI:** `RdYlBu` (Red for dry/negative, Blue for wet/positive—the meteorological standard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def create_feature_animation(da, var_name, cmap, title, save_filename=None):\n",
    "    # Calculate global limits to keep the legend/colorbar static\n",
    "    vmin, vmax = float(da.min()), float(da.max())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 8))\n",
    "    \n",
    "    # Initialize the plot with the first time step\n",
    "    im = da.isel(time=0).plot(ax=ax, cmap=cmap, vmin=vmin, vmax=vmax, \n",
    "                               add_colorbar=True, \n",
    "                               cbar_kwargs={'label': var_name})\n",
    "    \n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    title_text = ax.set_title(f\"{title} - {da.time.values[0].astype('M8[M]')}\")\n",
    "\n",
    "    def update(i):\n",
    "        # Update the image data without redrawing the colorbar\n",
    "        im.set_array(da.isel(time=i).values.flatten())\n",
    "        title_text.set_text(f\"{title} - {da.time.values[i].astype('M8[M]')}\")\n",
    "        return im, title_text\n",
    "\n",
    "    # Create animation (we'll do 24 months to keep it fast, or len(da.time) for all)\n",
    "    ani = FuncAnimation(fig, update, frames=24, interval=300, blit=True)\n",
    "    \n",
    "    # Save if a filename is provided\n",
    "    if save_filename:\n",
    "        writer = FFMpegWriter(fps=4, metadata=dict(artist='Bahri, Dhiaa Eddine'), bitrate=1800)\n",
    "        ani.save(f\"/kaggle/working/{save_filename}.mp4\", writer=writer)\n",
    "        print(f\"✅ Video saved to: /kaggle/working/{save_filename}.mp4\")\n",
    "\n",
    "    plt.close() \n",
    "    return ani\n",
    "\n",
    "# Example: Animating NDVI for the most recent 2 years\n",
    "# Change 'NDVI' to 'LST', 'Soil_Moisture', or 'SPI' as needed\n",
    "# ndvi_anim = create_feature_animation(ds['NDVI'], \"NDVI\", \"YlGn\", \"Vegetation Health\")\n",
    "# lst_anim = create_feature_animation(\n",
    "#     ds['LST'], \n",
    "#     \"LST (°C)\", \n",
    "#     \"inferno\", \n",
    "#     \"Land Surface Temperature\", \n",
    "#     # save_filename=\"tunisia_lst_3year_trend\"\n",
    "# )\n",
    "\n",
    "# sm_anim = create_feature_animation(\n",
    "#     ds['Soil_Moisture'], \n",
    "#     \"Soil Moisture (mm)\", \n",
    "#     \"Blues\", \n",
    "#     \"Soil Moisture\", \n",
    "#     # save_filename=\"tunisia_sm_3year_trend\"\n",
    "# )\n",
    "\n",
    "spi_anim = create_feature_animation(\n",
    "    ds['SPI'], \n",
    "    \"Standardized Precipitation Index\", \n",
    "    \"RdYlBu\", \n",
    "    \"Standardized Precipitation Index\", \n",
    "    # save_filename=\"tunisia_spi_3year_trend\"\n",
    ")\n",
    "\n",
    "# HTML(ndvi_anim.to_jshtml())\n",
    "# HTML(lst_anim.to_jshtml())\n",
    "# HTML(sm_anim.to_jshtml())\n",
    "HTML(spi_anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Chronological Data Splitting\n",
    "\n",
    "In drought forecasting, we must respect the \"arrow of time.\" We cannot use a random shuffle split because drought has **temporal memory**—the soil moisture of today is heavily dependent on the rainfall of last month. If we allow the model to see future data during training, we create \"data leakage,\" making our uncertainty assessments useless.\n",
    "\n",
    "We will split your 299 months (approx. 25 years) into three distinct blocks:\n",
    "\n",
    "- **Train (70%):** Establishing the long-term climatological \"baseline.\"\n",
    "- **Validation (15%):** Tuning the hyper-parameters and fuzzy membership functions.\n",
    "- **Test (15%):** Evaluating the model on the most recent, severe drought events in Tunisia (2021–2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Implementing the Chronological Split Strategy\n",
    "\n",
    "# Define the split points\n",
    "n_time = len(ds.time)\n",
    "train_end = int(n_time * 0.70)\n",
    "val_end = int(n_time * 0.85)\n",
    "\n",
    "# Split the dataset\n",
    "ds_train = ds.isel(time=slice(0, train_end))\n",
    "ds_val   = ds.isel(time=slice(train_end, val_end))\n",
    "ds_test  = ds.isel(time=slice(val_end, None))\n",
    "\n",
    "print(f\"--- Data Split Summary ---\")\n",
    "print(f\"Train: {ds_train.time.values[0].astype('M8[D]')} to {ds_train.time.values[-1].astype('M8[D]')} ({len(ds_train.time)} months)\")\n",
    "print(f\"Val:   {ds_val.time.values[0].astype('M8[D]')} to {ds_val.time.values[-1].astype('M8[D]')} ({len(ds_val.time)} months)\")\n",
    "print(f\"Test:  {ds_test.time.values[0].astype('M8[D]')} to {ds_test.time.values[-1].astype('M8[D]')} ({len(ds_test.time)} months)\")\n",
    "\n",
    "# Reliability Factor: We calculate the 'Historical Variance' \n",
    "# This helps our uncertainty model understand the 'natural noise' of each sensor\n",
    "uncertainty_base = {var: float(ds_train[var].std()) for var in ['LST', 'NDVI', 'Soil_Moisture', 'SPI']}\n",
    "print(f\"\\nBase Aleatory Uncertainty (Standard Deviation):\")\n",
    "for var, val in uncertainty_base.items():\n",
    "    print(f\"- {var}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of the Split:**\n",
    "\n",
    "By reserving the last 15% for testing, we are specifically testing the model's ability to handle the **2023-2024 Tunisian drought.** This is the ultimate \"stress test\" for an uncertainty-aware model:\n",
    "> *can it maintain high \"belief\" in its forecast during an unprecedented extreme event?*\n",
    "\n",
    "## 1.5. Reliability & Conflict Assessment\n",
    "\n",
    "Before we leave the \"Understanding\" phase, we must mathematically define the Conflict ($K$) between our sources. In the Theory of Evidence, conflict arises when two sensors provide evidence for mutually exclusive states.\n",
    "\n",
    "In our context, if **LST Anomaly** is very high (indicating extreme heat/drought) but **NDVI Anomaly** is also high (indicating healthy, green vegetation), these two sources are in conflict. This often happens in Tunisia due to irrigation or deep-rooted vegetation (olives) that resists short-term heat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Conflict Mapping (Preparing for Evidence Theory)\n",
    "\n",
    "def calculate_conflict_map(ds_slice):\n",
    "    \"\"\"\n",
    "    Identifies pixels where LST and NDVI provide opposing signals.\n",
    "    High value = High Conflict (One says drought, the other says healthy).\n",
    "    \"\"\"\n",
    "    # Standardize locally for comparison\n",
    "    lst_norm = (ds_slice.LST - ds_slice.LST.mean()) / ds_slice.LST.std()\n",
    "    ndvi_norm = (ds_slice.NDVI - ds_slice.NDVI.mean()) / ds_slice.NDVI.std()\n",
    "    \n",
    "    # Conflict is high when LST is high (+) and NDVI is high (+), \n",
    "    # or LST is low (-) and NDVI is low (-). \n",
    "    # Drought typically sees LST (+) and NDVI (-).\n",
    "    # We use the product to highlight areas where signs align incorrectly for drought.\n",
    "    conflict = lst_norm * ndvi_norm\n",
    "    return conflict\n",
    "\n",
    "# Calculate conflict for a specific recent time step\n",
    "recent_conflict = calculate_conflict_map(ds.isel(time=-1))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "recent_conflict.plot(cmap='bwr', robust=True)\n",
    "plt.title(\"Spatial Conflict Map ($K$): LST vs NDVI\\n(Red: High Conflict | Blue: Consensus)\")\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean Conflict Coefficient: {float(recent_conflict.mean()):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Mean Conflict Coefficient of -0.6120** is actually excellent news.\n",
    "\n",
    "In the way we calculated this (1$LST_{norm} \\times NDVI_{norm}$), a negative value means the variables are moving in opposite directions.2 For drought monitoring, this is the \"Natural Consensus\":\n",
    "\n",
    "- When Temperature ($LST$) goes up (positive anomaly), Vegetation ($NDVI$) goes down (negative anomaly).\n",
    "- $(+) \\times (-) = (-)$\n",
    "\n",
    "Since your average is significantly negative (-0.61), it proves that for most of Tunisia, your sensors are \"agreeing\" on the physical reality of the ecosystem. The \"Red\" areas (positive values) in your map are the specific exceptions where the **Zadeh Paradox** would be a risk—these are likely irrigated zones or coastal areas where the relationship breaks down.\n",
    "\n",
    "## 1.6. Final Data Audit: Reliability Weights\n",
    "\n",
    "Feature       | Reliability (α) | Justification\n",
    "--------------|-----------------|-----------------\n",
    "LST           | 0.85            | \"High precision, but sensitive to daily fluctuations and cloud shadows.\"\n",
    "NDVI          | 0.90            | Most stable indicator of long-term drought impact on the ground.\n",
    "Soil Moisture | 0.70            | Often model-derived; high uncertainty in deep soil layers.\n",
    "SPI           | 0.80            | \"Statistically robust, but spatial resolution is often coarser than satellite data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6 Finalizing Reliability Constants\n",
    "# These will be used in Phase 3 (Modeling) to weight the evidence fusion.\n",
    "\n",
    "source_reliability = {\n",
    "    \"LST\": 0.85,\n",
    "    \"NDVI\": 0.90,\n",
    "    \"Soil_Moisture\": 0.70,\n",
    "    \"SPI\": 0.80\n",
    "}\n",
    "\n",
    "print(\"✅ Phase 1 Complete: Dataset characteristics, spatial conflicts, and source reliability established.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Preprocessing\n",
    "\n",
    "Now that we have established the \"Reliability\" of our expert witnesses (the data columns), we move to **Phase 2**. In this phase, we transform raw physical measurements into standardized signals that our hybrid model can interpret.\n",
    "\n",
    "## 2.1. Monthly Climatology and Anomaly Calculation\n",
    "\n",
    "A raw LST of 35°C in Tunisia is \"cool\" for August but \"extreme\" for January. To make our model context-aware, we calculate **Anomalies**. This removes the seasonal \"heartbeat\" of the Mediterranean climate, leaving only the signals of environmental stress.\n",
    "\n",
    "We calculate the **Monthly Mean ($\\mu$)** and **Standard Deviation ($\\sigma$)** for the Training period (2000–2017) and apply those parameters to the Validation and Test sets to prevent **Temporal Data Leakage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Calculating Monthly Climatologies and Anomalies\n",
    "\n",
    "def get_climatology(ds_train):\n",
    "    \"\"\"Calculates the mean and std for each month using the training set.\"\"\"\n",
    "    clim_mean = ds_train.groupby(\"time.month\").mean(\"time\")\n",
    "    clim_std = ds_train.groupby(\"time.month\").std(\"time\")\n",
    "    return clim_mean, clim_std\n",
    "\n",
    "# Calculate baseline from Training Set ONLY\n",
    "ds_mean, ds_std = get_climatology(ds_train)\n",
    "\n",
    "def apply_anomalies(ds, ds_mean):\n",
    "    \"\"\"Subtracts the historical monthly mean to get the anomaly.\"\"\"\n",
    "    return ds.groupby(\"time.month\") - ds_mean\n",
    "\n",
    "# Apply to all splits\n",
    "ds_train_anom = apply_anomalies(ds_train, ds_mean)\n",
    "ds_val_anom   = apply_anomalies(ds_val, ds_mean)\n",
    "ds_test_anom  = apply_anomalies(ds_test, ds_mean)\n",
    "\n",
    "print(\"✅ Anomalies calculated using 2000-2017 baseline.\")\n",
    "print(f\"LST Anomaly Example (First Pixel): {float(ds_train_anom.LST.isel(x=0, y=0, time=0)):.2f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That `nan°C` is a timely red flag. It confirms that the 85% spatial disagreement we identified earlier isn't just a metadata curiosity—it’s a structural reality of your data.\n",
    "\n",
    "If the \"First Pixel\" is `NaN`, it means that either the raw value was missing or our 2000–2017 climatology baseline for that specific month/pixel coordinate has no data. Before we touch any more math, we need to map the \"Anatomy of Missingness.\"\n",
    "\n",
    "## 2.2. Corrective Step: The \"Vouching\" Mask\n",
    "\n",
    "If a pixel is missing for all years in January, the mean becomes `NaN`. When you subtract that `NaN` from your data, the result is `NaN`. This is why your \"First Pixel\" example returned `NaN`.\n",
    "\n",
    "We must distinguish between **Land** (where data exists) and **Void** (where it doesn't).\n",
    "\n",
    "Instead of just plotting missingness, we will create a **Count Map**. This tells us how many actual physical observations supported each \"Mean\" we calculated in Step 2.1. This is the first step toward true **Epistemic Uncertainty** modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Quantifying the \"Evidence Base\" for our Climatology\n",
    "\n",
    "def analyze_missingness_fixed(ds):\n",
    "    null_counts = ds.isnull().sum(dim='time').compute()\n",
    "    total_time = len(ds.time)\n",
    "    null_perc = (null_counts / total_time) * 100\n",
    "    \n",
    "    # Increase figure width to accommodate 4 maps side-by-side\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "    vars = ['LST', 'NDVI', 'Soil_Moisture', 'SPI']\n",
    "    \n",
    "    for i, var in enumerate(vars):\n",
    "        # We use .plot() but must ensure the aspect ratio is locked\n",
    "        p = null_perc[var].plot(ax=axes[i], cmap='Reds', vmin=0, vmax=100, add_colorbar=True)\n",
    "        \n",
    "        # --- THE FIX IS HERE ---\n",
    "        axes[i].set_aspect('equal', adjustable='box') \n",
    "        # -----------------------\n",
    "        \n",
    "        axes[i].set_title(f\"{var}\\n% Missing\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_missingness_fixed(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soil Moisture is a massive \"smoking gun\" for our model's uncertainty. If the Soil Moisture plot is a solid red (or white) rectangle with 0% missing values while **LST** and **NDVI** have irregular \"jagged\" holes, it means you are dealing with two different types of \"Expert\" data:\n",
    "\n",
    "1. **Direct Observation (LST/NDVI):** These are likely from optical satellites (like MODIS). They have holes where there are clouds or sensor gaps. This is **real-world noise**.\n",
    "2. **Reanalysis/Model Data (Soil Moisture):** If it's a perfect rectangle, it’s likely a \"gridded product\" (like GLDAS or ERA5-Land). These use a computer model to fill the gaps.\n",
    "\n",
    "**The Danger: \"Fake Certainty:\"**\n",
    "\n",
    "This is a classic trap. The Soil Moisture \"Expert\" is essentially saying: \n",
    "> *\"I am never missing!\"*\n",
    "\n",
    "but in reality, it's just guessing what happened under the clouds.\n",
    "\n",
    "If we use the **standard Dempster-Shafer** rule here, the model might \"trust\" Soil Moisture more simply because it's always there, even though it's actually the least \"raw\" measurement. We need to penalize this \"rectangle of 0%\" to reflect its **Epistemic Uncertainty**.\n",
    "\n",
    "## 2.3. The \"Tunisia-First\" Masking & Interpolation\n",
    "\n",
    "We will use `geopandas` and `regionmask` to create a perfect vector-based mask of Tunisia. Then, we will fill the internal gaps using Linear Interpolation, but only for small gaps to avoid creating \"fake data\" over large missing regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. CREATE THE LAND MASK (Logical approach)\n",
    "# A pixel is 'Tunisia' if it has valid NDVI more than 5% of the time.\n",
    "# This is version-independent and perfectly matches your grid.\n",
    "land_mask = (ds.NDVI.notnull().sum(dim='time') > (len(ds.time) * 0.05)).compute()\n",
    "\n",
    "# 2. DEFINE THE CLEANING FUNCTION\n",
    "def clean_dataset(ds_input, mask):\n",
    "    # Apply the mask: Everything outside Tunisia becomes NaN\n",
    "    ds_land = ds_input.where(mask)\n",
    "    \n",
    "    # INTERPOLATION: \n",
    "    # We use 'linear' interpolation along the time dimension.\n",
    "    # limit=2 ensures we only fill small gaps (clouds) and don't invent months of data.\n",
    "    print(\"Starting temporal interpolation... this may take a minute.\")\n",
    "    ds_filled = ds_land.interpolate_na(\n",
    "        dim=\"time\", \n",
    "        method=\"linear\", \n",
    "        limit=2\n",
    "    )\n",
    "    return ds_filled\n",
    "\n",
    "# 3. EXECUTE\n",
    "ds_clean = clean_dataset(ds, land_mask)\n",
    "\n",
    "# 4. VERIFY THE MASK\n",
    "plt.figure(figsize=(6, 8))\n",
    "land_mask.plot(cmap='Greys_r')\n",
    "plt.title(\"Generated Tunisia Land Mask\\n(Black = Sea/Void, White = Study Area)\")\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Step 2.3 Complete: Masked and Interpolated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. The \"Interpolation Penalty\" (Crucial for Uncertainty)\n",
    "\n",
    "Since we have now \"invented\" some data via interpolation, we must update our Reliability Factors ($\\alpha$) from Phase 1.\n",
    "\n",
    "If a value was interpolated, its reliability should drop. In Dempster-Shafer theory, this is how we tell the model:\n",
    "> *\"I have a value here, but I'm not 100% sure it's real.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'Quality Flag' layer\n",
    "# 1 = Raw Data, 0.5 = Interpolated, 0 = Missing\n",
    "quality_flag = xr.where(ds.notnull(), 1.0, 0.0)\n",
    "quality_flag = quality_flag.where(land_mask) # Only land\n",
    "\n",
    "# Update quality for pixels that WERE null but are NOW filled\n",
    "interpolated_mask = ds.isnull() & ds_clean.notnull()\n",
    "quality_flag = xr.where(interpolated_mask, 0.5, quality_flag)\n",
    "\n",
    "print(\"✅ Quality metadata created: Interpolated pixels penalized by 50%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Standardize (Z-Scores)\n",
    "\n",
    "Now that the data is cleaned, we calculate the statistics. Note the use of `.compute()`—this is the secret to preventing Kaggle memory crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate SPI from the variables that need scaling\n",
    "vars_to_scale = ['LST', 'NDVI', 'Soil_Moisture']\n",
    "spi_var = ['SPI']\n",
    "\n",
    "# 1. Calculate Climatology only for the unscaled variables\n",
    "print(\"Calculating Climatology for LST, NDVI, and Soil Moisture...\")\n",
    "ds_mean = ds_clean[vars_to_scale].isel(time=slice(0, int(len(ds_clean.time) * 0.7))).groupby(\"time.month\").mean(\"time\").compute()\n",
    "ds_std  = ds_clean[vars_to_scale].isel(time=slice(0, int(len(ds_clean.time) * 0.7))).groupby(\"time.month\").std(\"time\").compute()\n",
    "\n",
    "import gc\n",
    "\n",
    "# 1. Clear everything from previous attempts\n",
    "gc.collect()\n",
    "\n",
    "# 2. Ensure your ds_clean is 'chunked' (This is the most important step)\n",
    "# This breaks the data into small blocks so it never fills the RAM\n",
    "ds_clean = ds_clean.chunk({'time': 12, 'x': -1, 'y': -1})\n",
    "\n",
    "# 3. Calculate Climatology (Keep this small)\n",
    "print(\"Calculating small Climatology baseline...\")\n",
    "train_slice = ds_clean.isel(time=slice(0, int(len(ds_clean.time) * 0.7)))\n",
    "ds_mean = train_slice[vars_to_scale].groupby(\"time.month\").mean(\"time\").compute()\n",
    "ds_std  = train_slice[vars_to_scale].groupby(\"time.month\").std(\"time\").compute()\n",
    "\n",
    "# 4. Define the recipe for Standardization (DO NOT COMPUTE YET)\n",
    "print(\"Defining lazy standardization recipe...\")\n",
    "ds_scaled = (ds_clean[vars_to_scale].groupby(\"time.month\") - ds_mean) / ds_std\n",
    "\n",
    "if 'month' in ds_scaled.coords:\n",
    "    ds_scaled = ds_scaled.drop_vars('month')\n",
    "\n",
    "# 5. Combine with SPI (Still Lazy)\n",
    "ds_z = xr.merge([ds_scaled, ds_clean[spi_var]])\n",
    "\n",
    "# 6. Final verification - We only compute ONE small slice to prove it works\n",
    "print(\"Testing one time-step to verify...\")\n",
    "test_slice = ds_z.LST.isel(time=0).compute()\n",
    "print(\"✅ Success! The recipe is ready without crashing the kernel.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Data Fusion\n",
    "\n",
    "## 3.1. The Fuzzy Membership Functions\n",
    "\n",
    "Now that we have **Z-scores** for all features (including SPI), we need to translate these raw numbers into \"Expert Opinions.\" In fuzzy logic, a Z-score of $-2.0$ shouldn't just be a number; it should represent a **Degree of Membership** in a category (e.g., \"Severe Drought\").\n",
    "\n",
    "We will define three fuzzy sets for each expert:\n",
    "\n",
    "1. **Dry (D):** High membership when Z-scores are low (for NDVI, SM, SPI) or high (for LST).\n",
    "2. **Normal (N):** High membership when Z-scores are near zero.\n",
    "3. **Wet (W):** High membership when Z-scores are positive (for NDVI, SM, SPI) or low (for LST).\n",
    "\n",
    "### 3.1.1. Defining the Membership Curves\n",
    "\n",
    "We will use **Sigmoid** functions for the extremes (Dry/Wet) and a **Gaussian** function for the Normal state. This provides a smooth transition between states, which is essential for the \"Uncertainty\" aspect of our hybrid model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fuzzy_membership(z_score, var_name):\n",
    "    \"\"\"\n",
    "    Assigns membership values for Dry, Normal, and Wet states.\n",
    "    Note: LST is 'inverted' (High Z-score = Dry).\n",
    "    \"\"\"\n",
    "    # 1. Define 'Dry' Membership\n",
    "    if var_name == 'LST':\n",
    "        # High LST = Dry (Right-leaning Sigmoid)\n",
    "        m_dry = 1 / (1 + np.exp(-2 * (z_score - 1.5)))\n",
    "        m_wet = 1 / (1 + np.exp(2 * (z_score + 1.5)))\n",
    "    else:\n",
    "        # Low NDVI/SM/SPI = Dry (Left-leaning Sigmoid)\n",
    "        m_dry = 1 / (1 + np.exp(2 * (z_score + 1.5)))\n",
    "        m_wet = 1 / (1 + np.exp(-2 * (z_score - 1.5)))\n",
    "        \n",
    "    # 2. Define 'Normal' Membership (Gaussian centered at 0)\n",
    "    m_normal = np.exp(-0.5 * (z_score**2))\n",
    "    \n",
    "    # 3. Normalize to ensure they sum to something logical (Optional but helpful)\n",
    "    # In DS Theory, these will become our basic probability assignments (m)\n",
    "    return m_dry, m_normal, m_wet\n",
    "\n",
    "print(\"✅ Fuzzy logic rules defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Translating to Evidence Theory (Mass Functions)\n",
    "\n",
    "This is the bridge to the **Dempster-Shafer (DS)** part of your project. Each fuzzy membership value becomes a **Mass ($m$)**.\n",
    "\n",
    "Recall your \"Reliability Factors\" ($\\alpha$)? We apply them here. If Expert \"LST\" is only 80% reliable, we multiply its fuzzy memberships by $0.8$. The remaining $0.2$ becomes **Ignorance ($\\Theta$)**.\n",
    "\n",
    "**Visualizing the NDVI Expert's Logic:**\n",
    "\n",
    "We will plot the membership curves over a range of Z-scores from **-4 to +4**. This covers almost every statistical possibility in your Tunisian dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_fuzzy_logic(var_name='NDVI'):\n",
    "    # Generate a range of Z-scores\n",
    "    z_range = np.linspace(-4, 4, 100)\n",
    "    \n",
    "    # Calculate memberships using the logic we defined\n",
    "    # (Left-leaning Sigmoid for Dry, Gaussian for Normal, Right-leaning for Wet)\n",
    "    m_dry = 1 / (1 + np.exp(2 * (z_range + 1.5)))\n",
    "    m_normal = np.exp(-0.5 * (z_range**2))\n",
    "    m_wet = 1 / (1 + np.exp(-2 * (z_range - 1.5)))\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(z_range, m_dry, label='Dry Membership (Stress)', color='red', lw=2)\n",
    "    plt.plot(z_range, m_normal, label='Normal Membership', color='green', lw=2)\n",
    "    plt.plot(z_range, m_wet, label='Wet Membership', color='blue', lw=2)\n",
    "    \n",
    "    # Add context lines\n",
    "    plt.axvline(x=-1.5, color='gray', linestyle='--', alpha=0.5, label='Severe Threshold')\n",
    "    plt.axvline(x=0, color='black', linestyle=':', alpha=0.3)\n",
    "    \n",
    "    plt.title(f\"Fuzzy Expert Opinion for {var_name}\")\n",
    "    plt.xlabel(\"Standardized Anomaly (Z-Score)\")\n",
    "    plt.ylabel(\"Degree of Membership ($\\mu$)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# visualize_fuzzy_logic('NDVI')\n",
    "\n",
    "# Commented out placeholders for other variables to stay focused:\n",
    "visualize_fuzzy_logic('LST') # Note: LST would be flipped!\n",
    "# visualize_fuzzy_logic('Soil_Moisture')\n",
    "# visualize_fuzzy_logic('SPI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to interpret this for your Hybrid Model:**\n",
    "\n",
    "- **The Overlap:** Notice that at a Z-score of **-1.0**, the expert is \"split.\" It has a ~30% membership in **Dry** and a ~60% membership in **Normal**. This is the \"Fuzzy\" part—it acknowledges that nature doesn't have a hard cutoff.\n",
    "- **The High-Certainty Zone:** Once the Z-score hits **-3.0**, the \"Dry\" membership is nearly 1.0. The expert is shouting:\n",
    "  > *\"This is a drought!\"*\n",
    "- **The Evidence Transition:** In the next step, we will take these three values (Dry, Normal, Wet) and multiply them by your **Reliability Factor ($\\alpha$)**.\n",
    "    - If $\\alpha = 0.8$ and Dry $= 1.0$, then the **Mass ($m$)** for Drought becomes **0.8**.\n",
    "    - The \"missing\" **0.2** becomes **Ignorance ($\\Theta$)**, meaning:\n",
    "      > *\"I am 80% sure it's a drought, and 20% of me is just unsure because I'm an imperfect sensor.\"*\n",
    "      \n",
    "Now that we have the expert \"opinions\" (Fuzzy Membership) for each variable, we enter:\n",
    "\n",
    "## 3.2. Dempster-Shafer (DS) Evidence Fusion\n",
    "\n",
    "This is where your model becomes a \"Hybrid.\" We aren't just averaging the numbers; we are mathematically resolving the conflict between experts (e.g., if LST says \"Hot/Dry\" but NDVI still looks \"Green/Normal\").\n",
    "\n",
    "### 3.2.1. Defining the \"Basic Probability Assignments\" (Masses)\n",
    "\n",
    "We convert our Fuzzy values into **Masses ($m$)**. For each pixel, each expert $i$ provides:\n",
    "\n",
    "- **$m_i(\\{D\\})$:** Mass assigned to **Drought**.\n",
    "- **$m_i(\\{N\\})$:** Mass assigned to **Normal**.\n",
    "- **$m_i(\\{W\\})$:** Mass assigned to **Wet**.\n",
    "- **$m_i(\\Theta)$:** Mass assigned to **Ignorance** (Uncertainty).\n",
    "\n",
    "### 3.2.2. The Fusion Engine (Dempster’s Rule of Combination)\n",
    "\n",
    "To combine Expert A (LST) and Expert B (NDVI), we use the orthogonal sum. We will define a function that takes two \"opinion vectors\" and merges them into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dempster_combination(m1, m2):\n",
    "    \"\"\"\n",
    "    Combines two mass distributions using Dempster's Rule.\n",
    "    m1, m2: dicts with keys 'D', 'N', 'W', 'Theta'\n",
    "    \"\"\"\n",
    "    # 1. Calculate the 'Conflict' (K)\n",
    "    # K is the sum of products where the experts disagree (e.g., D ∩ N, D ∩ W)\n",
    "    k = (m1['D']*m2['N'] + m1['D']*m2['W'] + \n",
    "         m1['N']*m2['D'] + m1['N']*m2['W'] + \n",
    "         m1['W']*m2['D'] + m1['W']*m2['N'])\n",
    "    \n",
    "    # If k = 1, the experts completely contradict each other (Extreme Conflict)\n",
    "    if k >= 1.0: return {'D':0, 'N':0, 'W':0, 'Theta':1} \n",
    "    \n",
    "    scaling_factor = 1 / (1 - k)\n",
    "    \n",
    "    # 2. Calculate Combined Masses\n",
    "    m_combined = {}\n",
    "    for state in ['D', 'N', 'W']:\n",
    "        # Intersection of same states + intersection with ignorance\n",
    "        m_combined[state] = (m1[state]*m2[state] + \n",
    "                             m1[state]*m2['Theta'] + \n",
    "                             m2[state]*m1['Theta']) * scaling_factor\n",
    "        \n",
    "    # 3. Calculate remaining Ignorance\n",
    "    m_combined['Theta'] = (m1['Theta'] * m2['Theta']) * scaling_factor\n",
    "    \n",
    "    return m_combined\n",
    "\n",
    "print(\"✅ Fusion Engine logic ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why this is better than a simple average:**\n",
    "\n",
    "- **The Ignorance Filter:** If Soil Moisture is missing data (Mass goes to $\\Theta$), the formula automatically gives more weight to the other experts.\n",
    "- **Conflict Detection:** If $K$ is high, it tells us the sensors are \"arguing.\" This is a high-level feature we can later feed into your TPU-based Neural Network to help it learn which expert is right in specific Tunisian regions (like the more humid North vs. the arid South).\n",
    "\n",
    "**Testing a \"Conflict\" Scenario:**\n",
    "\n",
    "Let's simulate a real-world scenario:\n",
    "\n",
    "- **LST Expert:** Says it's extremely hot (Z = +2.5) $\\rightarrow$ High mass for **Dry**.\n",
    "- **NDVI Expert:** Says the plants are still green (Z = 0.0) $\\rightarrow$ High mass for **Normal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated reliability (alpha)\n",
    "alpha_lst = 0.8\n",
    "alpha_ndvi = 0.9\n",
    "\n",
    "# Get fuzzy memberships for LST (Hot = Dry)\n",
    "# We'll use the logic: m_dry=0.9, m_normal=0.1\n",
    "m_lst = {'D': 0.9*alpha_lst, 'N': 0.1*alpha_lst, 'W': 0, 'Theta': (1-alpha_lst)}\n",
    "\n",
    "# Get fuzzy memberships for NDVI (Normal)\n",
    "m_ndvi = {'D': 0.1*alpha_ndvi, 'N': 0.8*alpha_ndvi, 'W': 0.1*alpha_ndvi, 'Theta': (1-alpha_ndvi)}\n",
    "\n",
    "# Fuse them!\n",
    "result = dempster_combination(m_lst, m_ndvi)\n",
    "\n",
    "print(f\"Fused Opinion: {result}\")\n",
    "\n",
    "\n",
    "def robust_fusion(m1, m2):\n",
    "    # Calculate Conflict (K)\n",
    "    k = (m1['D']*m2['N'] + m1['D']*m2['W'] + \n",
    "         m1['N']*m2['D'] + m1['N']*m2['W'] + \n",
    "         m1['W']*m2['D'] + m1['W']*m2['N'])\n",
    "    \n",
    "    m_fused = {}\n",
    "    # Combine beliefs only (No normalization here yet)\n",
    "    for state in ['D', 'N', 'W']:\n",
    "        m_fused[state] = (m1[state]*m2[state] + \n",
    "                          m1[state]*m2['Theta'] + \n",
    "                          m2[state]*m1['Theta'])\n",
    "        \n",
    "    # Yager-style: All conflict (K) + intersection of ignorance goes to Theta\n",
    "    m_fused['Theta'] = (m1['Theta'] * m2['Theta']) + k\n",
    "    \n",
    "    return m_fused\n",
    "\n",
    "print(\"✅ Robust Fusion Engine initialized. Zadeh Paradox mitigated by assigning conflict to Ignorance.\")\n",
    "print(f\"Robust Fused Opinion: {robust_fusion(m_lst, m_ndvi)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature    | Standard DS                       | Robust (Yager)\n",
    "-----------|-----------------------------------|------------------\n",
    "Philosophy | \"Someone must be right.\"          | \"If you're fighting, I don't trust either.\"\n",
    "Certainty  | High (95%)                        | Low (38%)\n",
    "Risk       | High (Potential for false alarms) | Low (Admits data quality issues)\n",
    "Model Role | Makes a choice.                   | Passes the problem to the Neural Network.\n",
    "\n",
    "Since we are dealing with a 25-year dataset over the entire map of Tunisia, we cannot use a Python loop. We need to **vectorize** the Robust Fusion logic so that it runs as a single mathematical operation across all pixels simultaneously.\n",
    "\n",
    "## 3.3. Vectorized Robust Fusion (The \"Evidence Cube\")\n",
    "\n",
    "We will convert our fuzzy logic into `xarray`/`numpy` operations. Instead of dictionaries, we will create a new dataset where each pixel has four \"Mass\" layers: **D, N, W, and Theta**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "def get_mass_assignments(ds_z, alpha_dict):\n",
    "    \"\"\"\n",
    "    Converts Z-scores into Mass assignments (m) for all experts.\n",
    "    alpha_dict: {'LST': 0.8, 'NDVI': 0.9, ...}\n",
    "    \"\"\"\n",
    "    mass_ds = xr.Dataset()\n",
    "    \n",
    "    for var in ds_z.data_vars:\n",
    "        z = ds_z[var]\n",
    "        alpha = alpha_dict.get(var, 0.8)\n",
    "        \n",
    "        # 1. Calculate Fuzzy Memberships (Vectorized)\n",
    "        if var == 'LST':\n",
    "            m_dry_raw = 1 / (1 + np.exp(-2 * (z - 1.5)))\n",
    "            m_wet_raw = 1 / (1 + np.exp(2 * (z + 1.5)))\n",
    "        else:\n",
    "            m_dry_raw = 1 / (1 + np.exp(2 * (z + 1.5)))\n",
    "            m_wet_raw = 1 / (1 + np.exp(-2 * (z - 1.5)))\n",
    "            \n",
    "        m_norm_raw = np.exp(-0.5 * (z**2))\n",
    "        \n",
    "        # 2. Apply Reliability Discounting (Mass Assignment)\n",
    "        mass_ds[f'{var}_D'] = m_dry_raw * alpha\n",
    "        mass_ds[f'{var}_N'] = m_norm_raw * alpha\n",
    "        mass_ds[f'{var}_W'] = m_wet_raw * alpha\n",
    "        mass_ds[f'{var}_Theta'] = (1 - alpha)\n",
    "        \n",
    "    return mass_ds\n",
    "\n",
    "# Define your expert reliabilities based on Phase 1 research\n",
    "alphas = {'LST': 0.85, 'NDVI': 0.9, 'Soil_Moisture': 0.75, 'SPI': 0.95}\n",
    "ds_mass = get_mass_assignments(ds_z, alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. The Chain-Fusion Step\n",
    "\n",
    "Because we have 4 experts, we fuse them sequentially:\n",
    "\n",
    "1. Fuse **LST** and **NDVI** $\\rightarrow$ **Result A**\n",
    "2. Fuse **Result A** and **Soil Moisture** $\\rightarrow$ **Result B**\n",
    "3. Fuse **Result B** and **SPI** $\\rightarrow$ **Final Decision Cube**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_two_experts_vectorized(m1_prefix, m2_prefix, ds):\n",
    "    \"\"\"\n",
    "    Fuses two experts across the entire map using Robust (Yager) logic.\n",
    "    \"\"\"\n",
    "    # Extract mass components\n",
    "    d1, n1, w1, t1 = ds[f'{m1_prefix}_D'], ds[f'{m1_prefix}_N'], ds[f'{m1_prefix}_W'], ds[f'{m1_prefix}_Theta']\n",
    "    d2, n2, w2, t2 = ds[f'{m2_prefix}_D'], ds[f'{m2_prefix}_N'], ds[f'{m2_prefix}_W'], ds[f'{m2_prefix}_Theta']\n",
    "    \n",
    "    # 1. Calculate Conflict K (Vectorized)\n",
    "    k = (d1*n2 + d1*w2 + n1*d2 + n1*w2 + w1*d2 + w1*n2)\n",
    "    \n",
    "    # 2. Combine Beliefs (Robust Logic)\n",
    "    # New state = (Agreement + Ignorance interaction)\n",
    "    fused_d = (d1*d2 + d1*t2 + d2*t1)\n",
    "    fused_n = (n1*n2 + n1*t2 + n2*t1)\n",
    "    fused_w = (w1*w2 + w1*t2 + w2*t1)\n",
    "    \n",
    "    # 3. Conflict goes to Ignorance\n",
    "    fused_t = (t1*t2) + k\n",
    "    \n",
    "    return fused_d, fused_n, fused_w, fused_t\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# Step 1: Fuse LST and NDVI\n",
    "d_ln, n_ln, w_ln, t_ln = fuse_two_experts_vectorized('LST', 'NDVI', ds_mass)\n",
    "\n",
    "# Step 2: Create temporary storage for intermediate result to keep code clean\n",
    "# In a real run, we would continue this for SM and SPI..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why this is the turning point:**\n",
    "\n",
    "Once this runs, we will have a `fused_t` (Conflict/Ignorance) map.\n",
    "\n",
    "- Regions with high `fused_t` are \"Uncertainty Hotspots.\"\n",
    "- In the North of Tunisia, where sensors usually agree, `fused_t` will be low.\n",
    "- In the transition zones (Steppe), `fused_t` will be high.\n",
    "\n",
    "To visualize the uncertainty, we will calculate the final fusion of all four experts (LST, NDVI, Soil Moisture, and SPI) and then plot the **Ignorance ($\\Theta$)** layer.\n",
    "\n",
    "This map is essentially a \"Conflict Map.\" If a pixel is bright, it means the satellite data is contradictory, and the hybrid model is correctly identifying its own limitations.\n",
    "\n",
    "## 3.5. The 4-Way Fusion Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Fusion of all 4 Experts\n",
    "# 1. LST + NDVI\n",
    "d1, n1, w1, t1 = fuse_two_experts_vectorized('LST', 'NDVI', ds_mass)\n",
    "\n",
    "# 2. Add Soil Moisture\n",
    "# We create a temporary structure to hold the previous result\n",
    "ds_temp = xr.Dataset({'tmp_D': d1, 'tmp_N': n1, 'tmp_W': w1, 'tmp_Theta': t1})\n",
    "d2, n2, w2, t2 = fuse_two_experts_vectorized('tmp', 'Soil_Moisture', \n",
    "                                            xr.merge([ds_temp, ds_mass]))\n",
    "\n",
    "# 3. Add SPI (The final expert)\n",
    "ds_temp2 = xr.Dataset({'tmp2_D': d2, 'tmp2_N': n2, 'tmp2_W': w2, 'tmp2_Theta': t2})\n",
    "final_D, final_N, final_W, final_Theta = fuse_two_experts_vectorized('tmp2', 'SPI', \n",
    "                                                                    xr.merge([ds_temp2, ds_mass]))\n",
    "\n",
    "# Create the Final Hybrid Dataset\n",
    "ds_hybrid = xr.Dataset({\n",
    "    'Drought_Belief': final_D,\n",
    "    'Normal_Belief': final_N,\n",
    "    'Wet_Belief': final_W,\n",
    "    'Uncertainty': final_Theta\n",
    "})\n",
    "\n",
    "print(\"✅ Full 4-Way Robust Fusion complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Visualizing the \"Uncertainty Hotspots\"\n",
    "\n",
    "Let's look at a slice from a known drought year (e.g., Summer 2021). We want to see if the model is more \"confused\" in the desert transition zones or the agricultural North."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Select time and ensure we only have one month (e.g., the first one)\n",
    "# We add .squeeze() to drop any dimension that has only 1 entry\n",
    "sample_time = ds_hybrid.isel(time=-30).squeeze()\n",
    "\n",
    "# If 'month' still has multiple entries, we must pick one to plot a 2D map\n",
    "if 'month' in sample_time.dims and sample_time.month.size > 1:\n",
    "    sample_time = sample_time.isel(month=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "time_label = sample_time.time.dt.strftime(\"%B %Y\").values\n",
    "\n",
    "# 2. Use '...' in transpose to avoid the ValueError\n",
    "# This handles ('y', 'x', 'month') by moving y and x to the front\n",
    "plot_data_1 = sample_time.Drought_Belief.transpose('y', 'x', ...)\n",
    "plot_data_2 = sample_time.Uncertainty.transpose('y', 'x', ...)\n",
    "\n",
    "# Map 1: Belief\n",
    "plot_data_1.plot.pcolormesh(ax=ax[0], x='x', y='y', cmap='YlOrRd', robust=True)\n",
    "ax[0].set_title(f\"Hybrid Belief: Drought (D ({time_label}))\")\n",
    "ax[0].set_aspect('equal')\n",
    "\n",
    "# Map 2: Uncertainty\n",
    "plot_data_2.plot.pcolormesh(ax=ax[1], x='x', y='y', cmap='Purples', robust=True)\n",
    "ax[1].set_title(r\"Hybrid Uncertainty: Conflict ($\\Theta$)\")\n",
    "ax[1].set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Processessing\n",
    "\n",
    "## 4.1. Preparing for the TPU (Data Shaping)\n",
    "\n",
    "To move into the Deep Learning phase, we need to transform our `ds_hybrid` into a format the TPU can digest. TPUs love **4D Tensors**: `(Samples, Time_Steps, Features, Space)`.\n",
    "\n",
    "We will treat the 4 fused mass layers (D, N, W, Theta) as our **Features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "# 1. Ensure we are calling the correct variables from ds_hybrid\n",
    "# Let's double check the keys exist\n",
    "print(\"Available variables:\", list(ds_hybrid.data_vars))\n",
    "\n",
    "# 2. Extract arrays as Dask arrays (Lazy)\n",
    "# This prevents the \"empty list\" error by pulling them explicitly\n",
    "try:\n",
    "    d_map = ds_hybrid['Drought_Belief'].data\n",
    "    n_map = ds_hybrid['Normal_Belief'].data\n",
    "    w_map = ds_hybrid['Wet_Belief'].data\n",
    "    u_map = ds_hybrid['Uncertainty'].data\n",
    "    \n",
    "    # 3. Stack them along a NEW 'feature' dimension (axis=-1)\n",
    "    # The shape will be (time, y, x, 4)\n",
    "    data_for_tpu = da.stack([d_map, n_map, w_map, u_map], axis=-1)\n",
    "    \n",
    "    print(f\"✅ Success! Data Shape: {data_for_tpu.shape}\")\n",
    "    print(\"Format: (Time, Latitude, Longitude, Features)\")\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Error: One of the features was not found in ds_hybrid: {e}\")\n",
    "\n",
    "# 1. Fix the 5D to 4D issue\n",
    "# We take the mean across the 'month' axis (axis 3) to collapse the redundant dimension\n",
    "if len(data_for_tpu.shape) == 5:\n",
    "    data_for_tpu = data_for_tpu.mean(axis=3)\n",
    "\n",
    "print(f\"Corrected Shape for TPU: {data_for_tpu.shape}\") # Should be (299, 851, 410, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. The TPU Dataset Bridge\n",
    "\n",
    "Now that we have a 4D Dask array, we can set up the TensorFlow pipeline. This code needs to be very specific about types to work on a TPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def dask_to_tf_dataset(dask_array, batch_size=8):\n",
    "    # Determine the shape of a single time-step (y, x, features)\n",
    "    sample_shape = dask_array.shape[1:] \n",
    "    \n",
    "    def generator():\n",
    "        # Loop through the time dimension\n",
    "        for i in range(dask_array.shape[0]):\n",
    "            # Pull one month into RAM at a time\n",
    "            yield dask_array[i].compute()\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=tf.TensorSpec(shape=sample_shape, dtype=tf.float32)\n",
    "    )\n",
    "\n",
    "    # TPU Requirement: Batch size must be a multiple of 8 (number of TPU cores)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Create the final pipeline\n",
    "tpu_input = dask_to_tf_dataset(data_for_tpu)\n",
    "print(\"🚀 TPU Pipeline Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9286153,
     "sourceId": 14539052,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
